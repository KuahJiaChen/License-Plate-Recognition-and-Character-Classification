{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb6bdf9",
   "metadata": {},
   "source": [
    "# FIT3081 Image Processing- Assignment 2 (S1, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54963c6b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left\"> <h3> Student 1: Kuah Jia Chen, 32286988  </h3>  </div>\n",
    "<div style=\"text-align: left\"> <h3> Student 2: Samuel Tai Meng Yao, 32025068  </h3>  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d5d85",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa6dda",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This image processing project aims to develop a neural network-based solution for image classification and Malaysian car number plate recognition. The project is divided into three sections: training of the neural network program using manually cropped images, testing of the neural network program using the same set of images, and testing of Malaysian car number plate recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e52c53",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1. Overview\n",
    "2. Import Libraries\n",
    "3. Section 1: Training of the Neural Network Program using Manually Cropped Images\n",
    "4. Section 2: Testing of the Neural Network Program using Manually Cropped Images\n",
    "5. Section 3: Testing of Malaysian Car Number Plate Recognition\n",
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2480963",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5e4cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cf1ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the seed value for NumPy's random number generator\n",
    "This ensures that the random numbers generated will be the same every time the code is run\n",
    "\"\"\"\n",
    "# Seed value for reproducibility\n",
    "seed_value = 32286988\n",
    "\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb040e98",
   "metadata": {},
   "source": [
    "## Section 1: Training of the Neural Network Program using Manually Cropped Images\n",
    "\n",
    "In this section, the neural network program is trained using manually cropped images. The goal is to train the network to recognize and classify images accurately. The following parameters were used for training the neural network:\n",
    "\n",
    "- Numpy random seed: 32286988\n",
    "- Image height and width: 16\n",
    "- Number of hidden neurons in the hidden layer: 40\n",
    "- Error limit: 5e-05\n",
    "- Iteration limit: 500\n",
    "- Learning rate: 0.5\n",
    "\n",
    "The result of the training section indicates the effectiveness of the neural network model. Specifically, the target outputs for each training image (160 in total) are greater than or equal to 0.9, demonstrating that the network has learned to recognize the desired features. Additionally, the remaining 19 outputs are less than 0.1, indicating that the network has successfully learned to distinguish between different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41f68ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class TrainingNeuralNetwork:\n",
    "\n",
    "    def __init__(self, num_of_input, num_of_hidden, num_of_output, image_width, image_height):\n",
    "        \"\"\"\n",
    "        Initialize the neural network training parameters.\n",
    "\n",
    "        Args:\n",
    "        - num_of_input: Number of input neurons.\n",
    "        - num_of_hidden: Number of hidden neurons.\n",
    "        - num_of_output: Number of output neurons.\n",
    "        - image_width: Width of the input image.\n",
    "        - image_height: Height of the input image.\n",
    "        \"\"\"\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_hidden = num_of_hidden\n",
    "        self.num_of_output = num_of_output\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.wji = None\n",
    "        self.wkj = None\n",
    "        self.bias_j = None\n",
    "        self.bias_k = None\n",
    "        self.learning_rate = 0.5\n",
    "        self.error_total = math.inf\n",
    "        self.num_of_epoch = 0\n",
    "\n",
    "    def weight_initialization(self):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases of the neural network.\n",
    "        \"\"\"\n",
    "        # Initializing of the Weights.\n",
    "        # Random float number between -0.5 to 0.5.\n",
    "        self.wji = np.random.uniform(-0.5, 0.5, size=(self.num_of_hidden, self.num_of_input))\n",
    "        self.wkj = np.random.uniform(-0.5, 0.5, size=(self.num_of_output, self.num_of_hidden))\n",
    "        self.bias_j = np.random.uniform(0, 1, size=(self.num_of_hidden, 1))\n",
    "        self.bias_k = np.random.uniform(0, 1, size=(self.num_of_output, 1))\n",
    "        self.wji = np.array(self.wji)\n",
    "        self.wkj = np.array(self.wkj)\n",
    "        self.bias_j = np.array(self.bias_j)\n",
    "        self.bias_k = np.array(self.bias_k)\n",
    "\n",
    "    def set_current_X_train_y_train(self, current_X_train, current_y_train):\n",
    "        \"\"\"\n",
    "        Set the current training data.\n",
    "\n",
    "        Args:\n",
    "        - current_X_train: Current training input data.\n",
    "        - current_y_train: Current training output data.\n",
    "        \"\"\"\n",
    "        self.X_train = current_X_train\n",
    "        self.y_train = current_y_train\n",
    "        self.X_train = np.array(self.X_train)\n",
    "        self.X_train = self.X_train.reshape((self.X_train.shape[0], 1))\n",
    "        if current_y_train is not None:\n",
    "            self.y_train = np.array(self.y_train)\n",
    "            self.y_train = self.y_train.reshape((self.y_train.shape[0], 1))\n",
    "\n",
    "    def forward_input_hidden(self):\n",
    "        \"\"\"\n",
    "        Perform forward propagation from input to hidden layer.\n",
    "        \"\"\"\n",
    "        # Forward Propagation from Input -> Hidden Layer.\n",
    "        # Obtain the results at each neuron in the hidden layer\n",
    "        self.net_j = np.dot(self.wji, self.X_train)\n",
    "        self.out_j = 1 / (1 + np.exp(-(self.net_j + self.bias_j)))\n",
    "\n",
    "    def forward_hidden_output(self):\n",
    "        \"\"\"\n",
    "        Perform forward propagation from hidden to output layer.\n",
    "        \"\"\"\n",
    "        # Forward Propagation from Hidden -> Output Layer, j represents the neuron number at K Layer.\n",
    "        self.net_k = np.dot(self.wkj, self.out_j).reshape((-1, 1))\n",
    "        self.out_k = 1 / (1 + np.exp(-(self.net_k + self.bias_k)))\n",
    "\n",
    "    def error_correction(self):\n",
    "        \"\"\"\n",
    "        Calculate the error and return the current error and output values.\n",
    "        \"\"\"\n",
    "        # Error Correction.\n",
    "        self.current_error = (1 / 2) * np.sum((self.y_train - self.out_k) ** 2)\n",
    "        return self.current_error, self.out_k\n",
    "\n",
    "    def weight_bias_correction_output(self):\n",
    "        \"\"\"\n",
    "        Perform weight and bias correction between hidden and output layer.\n",
    "        \"\"\"\n",
    "        # Correction of Weights and Bias between Hidden and Output Layer.\n",
    "        self.delta_wk = (self.out_k - self.y_train) * self.out_k * (1 - self.out_k) * self.out_j.T\n",
    "        self.delta_bias_k = (self.out_k - self.y_train) * self.out_k * (1 - self.out_k)\n",
    "\n",
    "    def weight_bias_correction_hidden(self):\n",
    "        \"\"\"\n",
    "        Perform weight and bias correction between input and hidden layer.\n",
    "        \"\"\"\n",
    "        # Correction of Weights and Bias between Input and Hidden Layer.\n",
    "        self.delta_k_l = (self.out_k - self.y_train) * self.out_k * (1 - self.out_k)\n",
    "        test = (self.out_j * (1 - self.out_j))\n",
    "        test_1 = np.dot(self.delta_k_l.T, self.wkj).T\n",
    "        self.delta_wj = np.dot(self.X_train, test.T)\n",
    "        self.delta_wj = self.delta_wj.T * test_1\n",
    "\n",
    "        self.delta_bias_j = test * np.dot(self.delta_k_l.T, self.wkj).T\n",
    "\n",
    "    def weight_bias_update(self):\n",
    "        \"\"\"\n",
    "        Update the weights and biases.\n",
    "        \"\"\"\n",
    "        # Update Weights and Bias.\n",
    "        self.wji = self.wji - (self.learning_rate * self.delta_wj)\n",
    "        self.bias_j = self.bias_j - self.learning_rate * self.delta_bias_j\n",
    "\n",
    "        self.wkj = self.wkj - self.learning_rate * self.delta_wk\n",
    "        self.bias_k = self.bias_k - self.learning_rate * self.delta_bias_k\n",
    "\n",
    "    def check_for_end(self, epoch_set_by_user, error_set_by_user, global_error):\n",
    "        \"\"\"\n",
    "        Check if the training should end based on the given conditions.\n",
    "\n",
    "        Args:\n",
    "        - epoch_set_by_user: Number of epochs set by the user.\n",
    "        - error_set_by_user: Error threshold set by the user.\n",
    "        - global_error: Current global error.\n",
    "\n",
    "        Returns:\n",
    "        - True if training should end, False otherwise.\n",
    "        \"\"\"\n",
    "        self.num_of_epoch += 1\n",
    "        if self.num_of_epoch >= epoch_set_by_user or global_error <= error_set_by_user:\n",
    "            self.num_of_epoch = 0\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def saving_weight_bias(self):\n",
    "        \"\"\"\n",
    "        Save the weights and biases to a file.\n",
    "        \"\"\"\n",
    "        # Save the arrays to a file with custom names\n",
    "        np.savez('output_file.npz', wji=self.wji, wkj=self.wkj, bias_j=self.bias_j, bias_k=self.bias_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95ebdede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_read_files(folder, num_of_target, image_height, image_width):\n",
    "    \"\"\"\n",
    "    Function to read input and target files from a specified folder.\n",
    "    Args:\n",
    "    - folder: The directory path where the files are located.\n",
    "    - num_of_target: The number of target classes.\n",
    "    - image_height: The desired height of the image.\n",
    "    - image_width: The desired width of the image.\n",
    "    \"\"\"\n",
    "    # Initialize empty lists to store training data.\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Iterate over each file in the specified folder.\n",
    "    for image_file_name in os.listdir(folder):\n",
    "        file_name_path = folder + image_file_name\n",
    "\n",
    "        # Create a list to represent the target column for the current image.\n",
    "        current_target_column = [0] * num_of_target\n",
    "\n",
    "        # Set the print options to show the full array when printing.\n",
    "        np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "        # Read the current image file and convert it into an array.\n",
    "        current_image_array = training_read_image(file_name_path, image_height, image_width)\n",
    "\n",
    "        # Extract the target class from the image file name and update the target column.\n",
    "        if image_file_name[3] != \".\":\n",
    "            current_target_column[int(image_file_name[2:4])] = 1\n",
    "        else:\n",
    "            current_target_column[int(image_file_name[2])] = 1\n",
    "\n",
    "        # Append the current image array and target column to the training data.\n",
    "        X_train.append(current_image_array)\n",
    "        y_train.append(current_target_column)\n",
    "\n",
    "    # Return the training data.\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73542209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_read_image(file_path, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Read and preprocess an image for training.\n",
    "\n",
    "    Args:\n",
    "    - file_path: The path to the image file.\n",
    "    - image_width: The desired width of the image.\n",
    "    - image_height: The desired height of the image.\n",
    "\n",
    "    Returns:\n",
    "        The preprocessed image array.\n",
    "    \"\"\"\n",
    "    # Set numpy printing options to display the entire array\n",
    "\n",
    "    # Read the image as grayscale\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Resize the image if needed\n",
    "    image = cv2.resize(image, (image_width, image_height))\n",
    "\n",
    "    # Convert the 2D image array to 1D\n",
    "    image = image.flatten()\n",
    "\n",
    "    # Normalize the pixel values between 0 and 1\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "\n",
    "    # Return the preprocessed image array\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43abe9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 1th iteration\n",
      "current global error: 81.68962122547701\n",
      "\n",
      "running 2th iteration\n",
      "current global error: 65.23422984549399\n",
      "\n",
      "running 3th iteration\n",
      "current global error: 54.68430559323658\n",
      "\n",
      "running 4th iteration\n",
      "current global error: 47.82759955845569\n",
      "\n",
      "running 5th iteration\n",
      "current global error: 40.73839923311086\n",
      "\n",
      "running 6th iteration\n",
      "current global error: 31.705370584784013\n",
      "\n",
      "running 7th iteration\n",
      "current global error: 22.62378825862172\n",
      "\n",
      "running 8th iteration\n",
      "current global error: 16.562844751284086\n",
      "\n",
      "running 9th iteration\n",
      "current global error: 12.770404176043172\n",
      "\n",
      "running 10th iteration\n",
      "current global error: 10.188216178484945\n",
      "\n",
      "running 11th iteration\n",
      "current global error: 8.046744589373597\n",
      "\n",
      "running 12th iteration\n",
      "current global error: 6.243275470432356\n",
      "\n",
      "running 13th iteration\n",
      "current global error: 4.861738517157155\n",
      "\n",
      "running 14th iteration\n",
      "current global error: 3.897272310975187\n",
      "\n",
      "running 15th iteration\n",
      "current global error: 3.2508258699600927\n",
      "\n",
      "running 16th iteration\n",
      "current global error: 2.79844895045717\n",
      "\n",
      "running 17th iteration\n",
      "current global error: 2.4611304088755532\n",
      "\n",
      "running 18th iteration\n",
      "current global error: 2.1869970525570253\n",
      "\n",
      "running 19th iteration\n",
      "current global error: 1.9197106821699044\n",
      "\n",
      "running 20th iteration\n",
      "current global error: 1.6547639035491413\n",
      "\n",
      "running 21th iteration\n",
      "current global error: 1.447869239989481\n",
      "\n",
      "running 22th iteration\n",
      "current global error: 1.2984256954828577\n",
      "\n",
      "running 23th iteration\n",
      "current global error: 1.1812555616776466\n",
      "\n",
      "running 24th iteration\n",
      "current global error: 1.0844218750974512\n",
      "\n",
      "running 25th iteration\n",
      "current global error: 1.0021967195331747\n",
      "\n",
      "running 26th iteration\n",
      "current global error: 0.9311356916554804\n",
      "\n",
      "running 27th iteration\n",
      "current global error: 0.8689373812267995\n",
      "\n",
      "running 28th iteration\n",
      "current global error: 0.8139753088274362\n",
      "\n",
      "running 29th iteration\n",
      "current global error: 0.7650520449608292\n",
      "\n",
      "running 30th iteration\n",
      "current global error: 0.7212554630689181\n",
      "\n",
      "running 31th iteration\n",
      "current global error: 0.6818666998229149\n",
      "\n",
      "running 32th iteration\n",
      "current global error: 0.6463004899527851\n",
      "\n",
      "running 33th iteration\n",
      "current global error: 0.6140680554175134\n",
      "\n",
      "running 34th iteration\n",
      "current global error: 0.5847545537313484\n",
      "\n",
      "running 35th iteration\n",
      "current global error: 0.5580048852794921\n",
      "\n",
      "running 36th iteration\n",
      "current global error: 0.5335139072843803\n",
      "\n",
      "running 37th iteration\n",
      "current global error: 0.5110189352264288\n",
      "\n",
      "running 38th iteration\n",
      "current global error: 0.49029354714896145\n",
      "\n",
      "running 39th iteration\n",
      "current global error: 0.4711422817952724\n",
      "\n",
      "running 40th iteration\n",
      "current global error: 0.4533960643565737\n",
      "\n",
      "running 41th iteration\n",
      "current global error: 0.436908275316521\n",
      "\n",
      "running 42th iteration\n",
      "current global error: 0.4215513961990542\n",
      "\n",
      "running 43th iteration\n",
      "current global error: 0.40721416636639823\n",
      "\n",
      "running 44th iteration\n",
      "current global error: 0.39379918430370797\n",
      "\n",
      "running 45th iteration\n",
      "current global error: 0.381220889290813\n",
      "\n",
      "running 46th iteration\n",
      "current global error: 0.36940386469574876\n",
      "\n",
      "running 47th iteration\n",
      "current global error: 0.3582814110009028\n",
      "\n",
      "running 48th iteration\n",
      "current global error: 0.34779434393686415\n",
      "\n",
      "running 49th iteration\n",
      "current global error: 0.33788998002181025\n",
      "\n",
      "running 50th iteration\n",
      "current global error: 0.32852127801744824\n",
      "\n",
      "running 51th iteration\n",
      "current global error: 0.31964611018675787\n",
      "\n",
      "running 52th iteration\n",
      "current global error: 0.31122664178048903\n",
      "\n",
      "running 53th iteration\n",
      "current global error: 0.30322880096159677\n",
      "\n",
      "running 54th iteration\n",
      "current global error: 0.29562182449816554\n",
      "\n",
      "running 55th iteration\n",
      "current global error: 0.28837786711776364\n",
      "\n",
      "running 56th iteration\n",
      "current global error: 0.2814716645139873\n",
      "\n",
      "running 57th iteration\n",
      "current global error: 0.2748802417119273\n",
      "\n",
      "running 58th iteration\n",
      "current global error: 0.26858265990332636\n",
      "\n",
      "running 59th iteration\n",
      "current global error: 0.2625597960124488\n",
      "\n",
      "running 60th iteration\n",
      "current global error: 0.25679415019773555\n",
      "\n",
      "running 61th iteration\n",
      "current global error: 0.25126967727089483\n",
      "\n",
      "running 62th iteration\n",
      "current global error: 0.24597163865549435\n",
      "\n",
      "running 63th iteration\n",
      "current global error: 0.24088647203674385\n",
      "\n",
      "running 64th iteration\n",
      "current global error: 0.23600167629337085\n",
      "\n",
      "running 65th iteration\n",
      "current global error: 0.23130570966782812\n",
      "\n",
      "running 66th iteration\n",
      "current global error: 0.22678789943584757\n",
      "\n",
      "running 67th iteration\n",
      "current global error: 0.2224383615913729\n",
      "\n",
      "running 68th iteration\n",
      "current global error: 0.21824792927692171\n",
      "\n",
      "running 69th iteration\n",
      "current global error: 0.21420808886954723\n",
      "\n",
      "running 70th iteration\n",
      "current global error: 0.2103109227846282\n",
      "\n",
      "running 71th iteration\n",
      "current global error: 0.2065490581884204\n",
      "\n",
      "running 72th iteration\n",
      "current global error: 0.20291562091955007\n",
      "\n",
      "running 73th iteration\n",
      "current global error: 0.19940419401263124\n",
      "\n",
      "running 74th iteration\n",
      "current global error: 0.19600878029655006\n",
      "\n",
      "running 75th iteration\n",
      "current global error: 0.1927237686078526\n",
      "\n",
      "running 76th iteration\n",
      "current global error: 0.1895439032179387\n",
      "\n",
      "running 77th iteration\n",
      "current global error: 0.1864642561228377\n",
      "\n",
      "running 78th iteration\n",
      "current global error: 0.18348020188752365\n",
      "\n",
      "running 79th iteration\n",
      "current global error: 0.18058739477403213\n",
      "\n",
      "running 80th iteration\n",
      "current global error: 0.17778174791493703\n",
      "\n",
      "running 81th iteration\n",
      "current global error: 0.17505941432178393\n",
      "\n",
      "running 82th iteration\n",
      "current global error: 0.1724167695424605\n",
      "\n",
      "running 83th iteration\n",
      "current global error: 0.16985039580273115\n",
      "\n",
      "running 84th iteration\n",
      "current global error: 0.16735706748572335\n",
      "\n",
      "running 85th iteration\n",
      "current global error: 0.16493373781939633\n",
      "\n",
      "running 86th iteration\n",
      "current global error: 0.16257752665625977\n",
      "\n",
      "running 87th iteration\n",
      "current global error: 0.16028570924211727\n",
      "\n",
      "running 88th iteration\n",
      "current global error: 0.15805570588161935\n",
      "\n",
      "running 89th iteration\n",
      "current global error: 0.15588507241811156\n",
      "\n",
      "running 90th iteration\n",
      "current global error: 0.1537714914538355\n",
      "\n",
      "running 91th iteration\n",
      "current global error: 0.15171276424412003\n",
      "\n",
      "running 92th iteration\n",
      "current global error: 0.14970680320591712\n",
      "\n",
      "running 93th iteration\n",
      "current global error: 0.1477516249869992\n",
      "\n",
      "running 94th iteration\n",
      "current global error: 0.14584534404743343\n",
      "\n",
      "running 95th iteration\n",
      "current global error: 0.14398616670966635\n",
      "\n",
      "running 96th iteration\n",
      "current global error: 0.14217238563775694\n",
      "\n",
      "running 97th iteration\n",
      "current global error: 0.14040237471005365\n",
      "\n",
      "running 98th iteration\n",
      "current global error: 0.1386745842529671\n",
      "\n",
      "running 99th iteration\n",
      "current global error: 0.13698753660649665\n",
      "\n",
      "running 100th iteration\n",
      "current global error: 0.13533982199486624\n",
      "\n",
      "running 101th iteration\n",
      "current global error: 0.13373009467804367\n",
      "\n",
      "running 102th iteration\n",
      "current global error: 0.13215706936208899\n",
      "\n",
      "running 103th iteration\n",
      "current global error: 0.1306195178482457\n",
      "\n",
      "running 104th iteration\n",
      "current global error: 0.1291162659024399\n",
      "\n",
      "running 105th iteration\n",
      "current global error: 0.12764619032845442\n",
      "\n",
      "running 106th iteration\n",
      "current global error: 0.12620821622947706\n",
      "\n",
      "running 107th iteration\n",
      "current global error: 0.12480131444402605\n",
      "\n",
      "running 108th iteration\n",
      "current global error: 0.12342449914342679\n",
      "\n",
      "running 109th iteration\n",
      "current global error: 0.12207682557909248\n",
      "\n",
      "running 110th iteration\n",
      "current global error: 0.12075738796881318\n",
      "\n",
      "running 111th iteration\n",
      "current global error: 0.11946531751215271\n",
      "\n",
      "running 112th iteration\n",
      "current global error: 0.11819978052584029\n",
      "\n",
      "running 113th iteration\n",
      "current global error: 0.11695997669077894\n",
      "\n",
      "running 114th iteration\n",
      "current global error: 0.11574513740295046\n",
      "\n",
      "running 115th iteration\n",
      "current global error: 0.11455452422110338\n",
      "\n",
      "running 116th iteration\n",
      "current global error: 0.11338742740466244\n",
      "\n",
      "running 117th iteration\n",
      "current global error: 0.11224316453579944\n",
      "\n",
      "running 118th iteration\n",
      "current global error: 0.11112107922006843\n",
      "\n",
      "running 119th iteration\n",
      "current global error: 0.11002053986042849\n",
      "\n",
      "running 120th iteration\n",
      "current global error: 0.10894093849986516\n",
      "\n",
      "running 121th iteration\n",
      "current global error: 0.10788168972817276\n",
      "\n",
      "running 122th iteration\n",
      "current global error: 0.10684222964878881\n",
      "\n",
      "running 123th iteration\n",
      "current global error: 0.10582201490186566\n",
      "\n",
      "running 124th iteration\n",
      "current global error: 0.10482052174004304\n",
      "\n",
      "running 125th iteration\n",
      "current global error: 0.10383724515363395\n",
      "\n",
      "running 126th iteration\n",
      "current global error: 0.10287169804216989\n",
      "\n",
      "running 127th iteration\n",
      "current global error: 0.10192341042946676\n",
      "\n",
      "running 128th iteration\n",
      "current global error: 0.10099192871956562\n",
      "\n",
      "running 129th iteration\n",
      "current global error: 0.10007681499109079\n",
      "\n",
      "running 130th iteration\n",
      "current global error: 0.09917764632772791\n",
      "\n",
      "running 131th iteration\n",
      "current global error: 0.09829401418268814\n",
      "\n",
      "running 132th iteration\n",
      "current global error: 0.09742552377516031\n",
      "\n",
      "running 133th iteration\n",
      "current global error: 0.09657179351689163\n",
      "\n",
      "running 134th iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current global error: 0.0957324544671556\n",
      "\n",
      "running 135th iteration\n",
      "current global error: 0.09490714981448323\n",
      "\n",
      "running 136th iteration\n",
      "current global error: 0.09409553438363849\n",
      "\n",
      "running 137th iteration\n",
      "current global error: 0.09329727416641279\n",
      "\n",
      "running 138th iteration\n",
      "current global error: 0.09251204587491055\n",
      "\n",
      "running 139th iteration\n",
      "current global error: 0.091739536516078\n",
      "\n",
      "running 140th iteration\n",
      "current global error: 0.09097944298630586\n",
      "\n",
      "running 141th iteration\n",
      "current global error: 0.09023147168501011\n",
      "\n",
      "running 142th iteration\n",
      "current global error: 0.08949533814616566\n",
      "\n",
      "running 143th iteration\n",
      "current global error: 0.08877076668682461\n",
      "\n",
      "running 144th iteration\n",
      "current global error: 0.08805749007171526\n",
      "\n",
      "running 145th iteration\n",
      "current global error: 0.08735524919307096\n",
      "\n",
      "running 146th iteration\n",
      "current global error: 0.08666379276488693\n",
      "\n",
      "running 147th iteration\n",
      "current global error: 0.08598287703085522\n",
      "\n",
      "running 148th iteration\n",
      "current global error: 0.08531226548526663\n",
      "\n",
      "running 149th iteration\n",
      "current global error: 0.08465172860621753\n",
      "\n",
      "running 150th iteration\n",
      "current global error: 0.08400104360048898\n",
      "\n",
      "running 151th iteration\n",
      "current global error: 0.08335999415951172\n",
      "\n",
      "running 152th iteration\n",
      "current global error: 0.08272837022585632\n",
      "\n",
      "running 153th iteration\n",
      "current global error: 0.08210596776972542\n",
      "\n",
      "running 154th iteration\n",
      "current global error: 0.08149258857495001\n",
      "\n",
      "running 155th iteration\n",
      "current global error: 0.08088804003402408\n",
      "\n",
      "running 156th iteration\n",
      "current global error: 0.08029213495173455\n",
      "\n",
      "running 157th iteration\n",
      "current global error: 0.07970469135696984\n",
      "\n",
      "running 158th iteration\n",
      "current global error: 0.07912553232231283\n",
      "\n",
      "running 159th iteration\n",
      "current global error: 0.07855448579104433\n",
      "\n",
      "running 160th iteration\n",
      "current global error: 0.07799138441120727\n",
      "\n",
      "running 161th iteration\n",
      "current global error: 0.07743606537639475\n",
      "\n",
      "running 162th iteration\n",
      "current global error: 0.07688837027294936\n",
      "\n",
      "running 163th iteration\n",
      "current global error: 0.07634814493327306\n",
      "\n",
      "running 164th iteration\n",
      "current global error: 0.07581523929496625\n",
      "\n",
      "running 165th iteration\n",
      "current global error: 0.07528950726552569\n",
      "\n",
      "running 166th iteration\n",
      "current global error: 0.07477080659234984\n",
      "\n",
      "running 167th iteration\n",
      "current global error: 0.07425899873780867\n",
      "\n",
      "running 168th iteration\n",
      "current global error: 0.07375394875915015\n",
      "\n",
      "running 169th iteration\n",
      "current global error: 0.07325552519302699\n",
      "\n",
      "running 170th iteration\n",
      "current global error: 0.07276359994443683\n",
      "\n",
      "running 171th iteration\n",
      "current global error: 0.07227804817988204\n",
      "\n",
      "running 172th iteration\n",
      "current global error: 0.07179874822456149\n",
      "\n",
      "running 173th iteration\n",
      "current global error: 0.07132558146341984\n",
      "\n",
      "running 174th iteration\n",
      "current global error: 0.07085843224588637\n",
      "\n",
      "running 175th iteration\n",
      "current global error: 0.07039718779414277\n",
      "\n",
      "running 176th iteration\n",
      "current global error: 0.06994173811477028\n",
      "\n",
      "running 177th iteration\n",
      "current global error: 0.06949197591363125\n",
      "\n",
      "running 178th iteration\n",
      "current global error: 0.06904779651384695\n",
      "\n",
      "running 179th iteration\n",
      "current global error: 0.06860909777674322\n",
      "\n",
      "running 180th iteration\n",
      "current global error: 0.06817578002563819\n",
      "\n",
      "running 181th iteration\n",
      "current global error: 0.06774774597235371\n",
      "\n",
      "running 182th iteration\n",
      "current global error: 0.06732490064633816\n",
      "\n",
      "running 183th iteration\n",
      "current global error: 0.06690715132629392\n",
      "\n",
      "running 184th iteration\n",
      "current global error: 0.0664944074742047\n",
      "\n",
      "running 185th iteration\n",
      "current global error: 0.0660865806716678\n",
      "\n",
      "running 186th iteration\n",
      "current global error: 0.06568358455843598\n",
      "\n",
      "running 187th iteration\n",
      "current global error: 0.06528533477308168\n",
      "\n",
      "running 188th iteration\n",
      "current global error: 0.06489174889569703\n",
      "\n",
      "running 189th iteration\n",
      "current global error: 0.06450274639255071\n",
      "\n",
      "running 190th iteration\n",
      "current global error: 0.06411824856262194\n",
      "\n",
      "running 191th iteration\n",
      "current global error: 0.06373817848594016\n",
      "\n",
      "running 192th iteration\n",
      "current global error: 0.06336246097365787\n",
      "\n",
      "running 193th iteration\n",
      "current global error: 0.0629910225197905\n",
      "\n",
      "running 194th iteration\n",
      "current global error: 0.06262379125455807\n",
      "\n",
      "running 195th iteration\n",
      "current global error: 0.06226069689926745\n",
      "\n",
      "running 196th iteration\n",
      "current global error: 0.06190167072267619\n",
      "\n",
      "running 197th iteration\n",
      "current global error: 0.06154664549878138\n",
      "\n",
      "running 198th iteration\n",
      "current global error: 0.061195555465979906\n",
      "\n",
      "running 199th iteration\n",
      "current global error: 0.06084833628754796\n",
      "\n",
      "running 200th iteration\n",
      "current global error: 0.06050492501339137\n",
      "\n",
      "running 201th iteration\n",
      "current global error: 0.06016526004301842\n",
      "\n",
      "running 202th iteration\n",
      "current global error: 0.059829281089690135\n",
      "\n",
      "running 203th iteration\n",
      "current global error: 0.05949692914570475\n",
      "\n",
      "running 204th iteration\n",
      "current global error: 0.05916814644877568\n",
      "\n",
      "running 205th iteration\n",
      "current global error: 0.05884287644946061\n",
      "\n",
      "running 206th iteration\n",
      "current global error: 0.05852106377960685\n",
      "\n",
      "running 207th iteration\n",
      "current global error: 0.058202654221773197\n",
      "\n",
      "running 208th iteration\n",
      "current global error: 0.057887594679595616\n",
      "\n",
      "running 209th iteration\n",
      "current global error: 0.057575833149061374\n",
      "\n",
      "running 210th iteration\n",
      "current global error: 0.05726731869066015\n",
      "\n",
      "running 211th iteration\n",
      "current global error: 0.05696200140238137\n",
      "\n",
      "running 212th iteration\n",
      "current global error: 0.05665983239352642\n",
      "\n",
      "running 213th iteration\n",
      "current global error: 0.056360763759309894\n",
      "\n",
      "running 214th iteration\n",
      "current global error: 0.0560647485562189\n",
      "\n",
      "running 215th iteration\n",
      "current global error: 0.055771740778107634\n",
      "\n",
      "running 216th iteration\n",
      "current global error: 0.05548169533299934\n",
      "\n",
      "running 217th iteration\n",
      "current global error: 0.05519456802057258\n",
      "\n",
      "running 218th iteration\n",
      "current global error: 0.054910315510307645\n",
      "\n",
      "running 219th iteration\n",
      "current global error: 0.054628895320271945\n",
      "\n",
      "running 220th iteration\n",
      "current global error: 0.05435026579652099\n",
      "\n",
      "running 221th iteration\n",
      "current global error: 0.05407438609309563\n",
      "\n",
      "running 222th iteration\n",
      "current global error: 0.053801216152595005\n",
      "\n",
      "running 223th iteration\n",
      "current global error: 0.05353071668730604\n",
      "\n",
      "running 224th iteration\n",
      "current global error: 0.05326284916087079\n",
      "\n",
      "running 225th iteration\n",
      "current global error: 0.05299757577047453\n",
      "\n",
      "running 226th iteration\n",
      "current global error: 0.05273485942953665\n",
      "\n",
      "running 227th iteration\n",
      "current global error: 0.05247466375088827\n",
      "\n",
      "running 228th iteration\n",
      "current global error: 0.05221695303042081\n",
      "\n",
      "running 229th iteration\n",
      "current global error: 0.05196169223119007\n",
      "\n",
      "running 230th iteration\n",
      "current global error: 0.051708846967960916\n",
      "\n",
      "running 231th iteration\n",
      "current global error: 0.05145838349217917\n",
      "\n",
      "running 232th iteration\n",
      "current global error: 0.051210268677355876\n",
      "\n",
      "running 233th iteration\n",
      "current global error: 0.05096447000485167\n",
      "\n",
      "running 234th iteration\n",
      "current global error: 0.050720955550048324\n",
      "\n",
      "running 235th iteration\n",
      "current global error: 0.05047969396889532\n",
      "\n",
      "running 236th iteration\n",
      "current global error: 0.050240654484819236\n",
      "\n",
      "running 237th iteration\n",
      "current global error: 0.05000380687598526\n",
      "\n",
      "running 238th iteration\n",
      "current global error: 0.04976912146289925\n",
      "\n",
      "running 239th iteration\n",
      "current global error: 0.049536569096340306\n",
      "\n",
      "running 240th iteration\n",
      "current global error: 0.04930612114561288\n",
      "\n",
      "running 241th iteration\n",
      "current global error: 0.04907774948710988\n",
      "\n",
      "running 242th iteration\n",
      "current global error: 0.048851426493175566\n",
      "\n",
      "running 243th iteration\n",
      "current global error: 0.048627125021260785\n",
      "\n",
      "running 244th iteration\n",
      "current global error: 0.04840481840336013\n",
      "\n",
      "running 245th iteration\n",
      "current global error: 0.04818448043572385\n",
      "\n",
      "running 246th iteration\n",
      "current global error: 0.04796608536883544\n",
      "\n",
      "running 247th iteration\n",
      "current global error: 0.04774960789764686\n",
      "\n",
      "running 248th iteration\n",
      "current global error: 0.04753502315206445\n",
      "\n",
      "running 249th iteration\n",
      "current global error: 0.047322306687677285\n",
      "\n",
      "running 250th iteration\n",
      "current global error: 0.047111434476721226\n",
      "\n",
      "running 251th iteration\n",
      "current global error: 0.046902382899271546\n",
      "\n",
      "running 252th iteration\n",
      "current global error: 0.04669512873465773\n",
      "\n",
      "running 253th iteration\n",
      "current global error: 0.04648964915309338\n",
      "\n",
      "running 254th iteration\n",
      "current global error: 0.046285921707515526\n",
      "\n",
      "running 255th iteration\n",
      "current global error: 0.04608392432562709\n",
      "\n",
      "running 256th iteration\n",
      "current global error: 0.04588363530213639\n",
      "\n",
      "running 257th iteration\n",
      "current global error: 0.045685033291188504\n",
      "\n",
      "running 258th iteration\n",
      "current global error: 0.04548809729898234\n",
      "\n",
      "running 259th iteration\n",
      "current global error: 0.045292806676569014\n",
      "\n",
      "running 260th iteration\n",
      "current global error: 0.04509914111282534\n",
      "\n",
      "running 261th iteration\n",
      "current global error: 0.044907080627598496\n",
      "\n",
      "running 262th iteration\n",
      "current global error: 0.04471660556501611\n",
      "\n",
      "running 263th iteration\n",
      "current global error: 0.04452769658695773\n",
      "\n",
      "running 264th iteration\n",
      "current global error: 0.04434033466668353\n",
      "\n",
      "running 265th iteration\n",
      "current global error: 0.044154501082614185\n",
      "\n",
      "running 266th iteration\n",
      "current global error: 0.043970177412259864\n",
      "\n",
      "running 267th iteration\n",
      "current global error: 0.043787345526293237\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 268th iteration\n",
      "current global error: 0.04360598758276191\n",
      "\n",
      "running 269th iteration\n",
      "current global error: 0.04342608602143734\n",
      "\n",
      "running 270th iteration\n",
      "current global error: 0.0432476235582966\n",
      "\n",
      "running 271th iteration\n",
      "current global error: 0.043070583180132835\n",
      "\n",
      "running 272th iteration\n",
      "current global error: 0.04289494813929067\n",
      "\n",
      "running 273th iteration\n",
      "current global error: 0.04272070194852449\n",
      "\n",
      "running 274th iteration\n",
      "current global error: 0.04254782837597473\n",
      "\n",
      "running 275th iteration\n",
      "current global error: 0.04237631144026022\n",
      "\n",
      "running 276th iteration\n",
      "current global error: 0.042206135405682466\n",
      "\n",
      "running 277th iteration\n",
      "current global error: 0.04203728477754013\n",
      "\n",
      "running 278th iteration\n",
      "current global error: 0.04186974429754924\n",
      "\n",
      "running 279th iteration\n",
      "current global error: 0.04170349893936814\n",
      "\n",
      "running 280th iteration\n",
      "current global error: 0.041538533904222706\n",
      "\n",
      "running 281th iteration\n",
      "current global error: 0.041374834616629996\n",
      "\n",
      "running 282th iteration\n",
      "current global error: 0.04121238672021835\n",
      "\n",
      "running 283th iteration\n",
      "current global error: 0.0410511760736402\n",
      "\n",
      "running 284th iteration\n",
      "current global error: 0.04089118874657626\n",
      "\n",
      "running 285th iteration\n",
      "current global error: 0.04073241101582751\n",
      "\n",
      "running 286th iteration\n",
      "current global error: 0.04057482936149458\n",
      "\n",
      "running 287th iteration\n",
      "current global error: 0.04041843046324048\n",
      "\n",
      "running 288th iteration\n",
      "current global error: 0.040263201196635255\n",
      "\n",
      "running 289th iteration\n",
      "current global error: 0.04010912862958084\n",
      "\n",
      "running 290th iteration\n",
      "current global error: 0.03995620001881344\n",
      "\n",
      "running 291th iteration\n",
      "current global error: 0.039804402806481926\n",
      "\n",
      "running 292th iteration\n",
      "current global error: 0.0396537246168004\n",
      "\n",
      "running 293th iteration\n",
      "current global error: 0.03950415325277203\n",
      "\n",
      "running 294th iteration\n",
      "current global error: 0.03935567669298433\n",
      "\n",
      "running 295th iteration\n",
      "current global error: 0.03920828308847206\n",
      "\n",
      "running 296th iteration\n",
      "current global error: 0.03906196075964736\n",
      "\n",
      "running 297th iteration\n",
      "current global error: 0.038916698193295185\n",
      "\n",
      "running 298th iteration\n",
      "current global error: 0.03877248403963197\n",
      "\n",
      "running 299th iteration\n",
      "current global error: 0.038629307109426594\n",
      "\n",
      "running 300th iteration\n",
      "current global error: 0.03848715637118164\n",
      "\n",
      "running 301th iteration\n",
      "current global error: 0.038346020948374096\n",
      "\n",
      "running 302th iteration\n",
      "current global error: 0.038205890116752815\n",
      "\n",
      "running 303th iteration\n",
      "current global error: 0.038066753301693346\n",
      "\n",
      "running 304th iteration\n",
      "current global error: 0.037928600075606514\n",
      "\n",
      "running 305th iteration\n",
      "current global error: 0.03779142015540106\n",
      "\n",
      "running 306th iteration\n",
      "current global error: 0.037655203399998664\n",
      "\n",
      "running 307th iteration\n",
      "current global error: 0.03751993980789938\n",
      "\n",
      "running 308th iteration\n",
      "current global error: 0.03738561951479752\n",
      "\n",
      "running 309th iteration\n",
      "current global error: 0.03725223279124554\n",
      "\n",
      "running 310th iteration\n",
      "current global error: 0.037119770040365783\n",
      "\n",
      "running 311th iteration\n",
      "current global error: 0.03698822179560849\n",
      "\n",
      "running 312th iteration\n",
      "current global error: 0.036857578718554614\n",
      "\n",
      "running 313th iteration\n",
      "current global error: 0.03672783159676363\n",
      "\n",
      "running 314th iteration\n",
      "current global error: 0.03659897134166379\n",
      "\n",
      "running 315th iteration\n",
      "current global error: 0.03647098898648446\n",
      "\n",
      "running 316th iteration\n",
      "current global error: 0.036343875684230635\n",
      "\n",
      "running 317th iteration\n",
      "current global error: 0.03621762270569617\n",
      "\n",
      "running 318th iteration\n",
      "current global error: 0.036092221437517655\n",
      "\n",
      "running 319th iteration\n",
      "current global error: 0.035967663380265795\n",
      "\n",
      "running 320th iteration\n",
      "current global error: 0.03584394014657474\n",
      "\n",
      "running 321th iteration\n",
      "current global error: 0.03572104345930789\n",
      "\n",
      "running 322th iteration\n",
      "current global error: 0.03559896514975953\n",
      "\n",
      "running 323th iteration\n",
      "current global error: 0.03547769715589143\n",
      "\n",
      "running 324th iteration\n",
      "current global error: 0.03535723152060404\n",
      "\n",
      "running 325th iteration\n",
      "current global error: 0.03523756039004035\n",
      "\n",
      "running 326th iteration\n",
      "current global error: 0.03511867601192334\n",
      "\n",
      "running 327th iteration\n",
      "current global error: 0.035000570733924714\n",
      "\n",
      "running 328th iteration\n",
      "current global error: 0.03488323700206507\n",
      "\n",
      "running 329th iteration\n",
      "current global error: 0.03476666735914514\n",
      "\n",
      "running 330th iteration\n",
      "current global error: 0.03465085444320578\n",
      "\n",
      "running 331th iteration\n",
      "current global error: 0.03453579098601827\n",
      "\n",
      "running 332th iteration\n",
      "current global error: 0.03442146981160284\n",
      "\n",
      "running 333th iteration\n",
      "current global error: 0.03430788383477469\n",
      "\n",
      "running 334th iteration\n",
      "current global error: 0.034195026059718095\n",
      "\n",
      "running 335th iteration\n",
      "current global error: 0.03408288957858652\n",
      "\n",
      "running 336th iteration\n",
      "current global error: 0.0339714675701296\n",
      "\n",
      "running 337th iteration\n",
      "current global error: 0.033860753298345043\n",
      "\n",
      "running 338th iteration\n",
      "current global error: 0.03375074011115587\n",
      "\n",
      "running 339th iteration\n",
      "current global error: 0.03364142143911239\n",
      "\n",
      "running 340th iteration\n",
      "current global error: 0.033532790794117674\n",
      "\n",
      "running 341th iteration\n",
      "current global error: 0.0334248417681767\n",
      "\n",
      "running 342th iteration\n",
      "current global error: 0.03331756803216874\n",
      "\n",
      "running 343th iteration\n",
      "current global error: 0.033210963334641457\n",
      "\n",
      "running 344th iteration\n",
      "current global error: 0.03310502150062782\n",
      "\n",
      "running 345th iteration\n",
      "current global error: 0.0329997364304839\n",
      "\n",
      "running 346th iteration\n",
      "current global error: 0.03289510209874835\n",
      "\n",
      "running 347th iteration\n",
      "current global error: 0.03279111255302179\n",
      "\n",
      "running 348th iteration\n",
      "current global error: 0.03268776191286692\n",
      "\n",
      "running 349th iteration\n",
      "current global error: 0.03258504436872836\n",
      "\n",
      "running 350th iteration\n",
      "current global error: 0.032482954180871416\n",
      "\n",
      "running 351th iteration\n",
      "current global error: 0.032381485678340295\n",
      "\n",
      "running 352th iteration\n",
      "current global error: 0.032280633257934815\n",
      "\n",
      "running 353th iteration\n",
      "current global error: 0.03218039138320459\n",
      "\n",
      "running 354th iteration\n",
      "current global error: 0.0320807545834624\n",
      "\n",
      "running 355th iteration\n",
      "current global error: 0.031981717452813495\n",
      "\n",
      "running 356th iteration\n",
      "current global error: 0.03188327464920295\n",
      "\n",
      "running 357th iteration\n",
      "current global error: 0.03178542089347955\n",
      "\n",
      "running 358th iteration\n",
      "current global error: 0.03168815096847567\n",
      "\n",
      "running 359th iteration\n",
      "current global error: 0.03159145971810372\n",
      "\n",
      "running 360th iteration\n",
      "current global error: 0.03149534204646811\n",
      "\n",
      "running 361th iteration\n",
      "current global error: 0.03139979291699244\n",
      "\n",
      "running 362th iteration\n",
      "current global error: 0.031304807351562235\n",
      "\n",
      "running 363th iteration\n",
      "current global error: 0.031210380429681973\n",
      "\n",
      "running 364th iteration\n",
      "current global error: 0.031116507287646845\n",
      "\n",
      "running 365th iteration\n",
      "current global error: 0.03102318311772901\n",
      "\n",
      "running 366th iteration\n",
      "current global error: 0.03093040316737729\n",
      "\n",
      "running 367th iteration\n",
      "current global error: 0.030838162738430607\n",
      "\n",
      "running 368th iteration\n",
      "current global error: 0.03074645718634513\n",
      "\n",
      "running 369th iteration\n",
      "current global error: 0.0306552819194343\n",
      "\n",
      "running 370th iteration\n",
      "current global error: 0.03056463239812159\n",
      "\n",
      "running 371th iteration\n",
      "current global error: 0.030474504134206184\n",
      "\n",
      "running 372th iteration\n",
      "current global error: 0.030384892690140757\n",
      "\n",
      "running 373th iteration\n",
      "current global error: 0.03029579367832139\n",
      "\n",
      "running 374th iteration\n",
      "current global error: 0.030207202760389653\n",
      "\n",
      "running 375th iteration\n",
      "current global error: 0.030119115646545878\n",
      "\n",
      "running 376th iteration\n",
      "current global error: 0.030031528094874232\n",
      "\n",
      "running 377th iteration\n",
      "current global error: 0.029944435910678805\n",
      "\n",
      "running 378th iteration\n",
      "current global error: 0.029857834945830827\n",
      "\n",
      "running 379th iteration\n",
      "current global error: 0.02977172109812638\n",
      "\n",
      "running 380th iteration\n",
      "current global error: 0.029686090310655118\n",
      "\n",
      "running 381th iteration\n",
      "current global error: 0.029600938571178858\n",
      "\n",
      "running 382th iteration\n",
      "current global error: 0.029516261911520843\n",
      "\n",
      "running 383th iteration\n",
      "current global error: 0.029432056406964405\n",
      "\n",
      "running 384th iteration\n",
      "current global error: 0.029348318175662042\n",
      "\n",
      "running 385th iteration\n",
      "current global error: 0.02926504337805374\n",
      "\n",
      "running 386th iteration\n",
      "current global error: 0.029182228216294424\n",
      "\n",
      "running 387th iteration\n",
      "current global error: 0.029099868933691535\n",
      "\n",
      "running 388th iteration\n",
      "current global error: 0.02901796181415079\n",
      "\n",
      "running 389th iteration\n",
      "current global error: 0.028936503181631153\n",
      "\n",
      "running 390th iteration\n",
      "current global error: 0.02885548939960883\n",
      "\n",
      "running 391th iteration\n",
      "current global error: 0.02877491687054932\n",
      "\n",
      "running 392th iteration\n",
      "current global error: 0.02869478203538829\n",
      "\n",
      "running 393th iteration\n",
      "current global error: 0.028615081373020636\n",
      "\n",
      "running 394th iteration\n",
      "current global error: 0.02853581139979722\n",
      "\n",
      "running 395th iteration\n",
      "current global error: 0.028456968669030382\n",
      "\n",
      "running 396th iteration\n",
      "current global error: 0.028378549770506377\n",
      "\n",
      "running 397th iteration\n",
      "current global error: 0.02830055133000623\n",
      "\n",
      "running 398th iteration\n",
      "current global error: 0.02822297000883339\n",
      "\n",
      "running 399th iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current global error: 0.02814580250334958\n",
      "\n",
      "running 400th iteration\n",
      "current global error: 0.02806904554451718\n",
      "\n",
      "running 401th iteration\n",
      "current global error: 0.027992695897449116\n",
      "\n",
      "running 402th iteration\n",
      "current global error: 0.02791675036096579\n",
      "\n",
      "running 403th iteration\n",
      "current global error: 0.02784120576715846\n",
      "\n",
      "running 404th iteration\n",
      "current global error: 0.02776605898096002\n",
      "\n",
      "running 405th iteration\n",
      "current global error: 0.02769130689972157\n",
      "\n",
      "running 406th iteration\n",
      "current global error: 0.027616946452796498\n",
      "\n",
      "running 407th iteration\n",
      "current global error: 0.02754297460112987\n",
      "\n",
      "running 408th iteration\n",
      "current global error: 0.02746938833685506\n",
      "\n",
      "running 409th iteration\n",
      "current global error: 0.027396184682895796\n",
      "\n",
      "running 410th iteration\n",
      "current global error: 0.027323360692574825\n",
      "\n",
      "running 411th iteration\n",
      "current global error: 0.027250913449228073\n",
      "\n",
      "running 412th iteration\n",
      "current global error: 0.02717884006582496\n",
      "\n",
      "running 413th iteration\n",
      "current global error: 0.02710713768459435\n",
      "\n",
      "running 414th iteration\n",
      "current global error: 0.02703580347665599\n",
      "\n",
      "running 415th iteration\n",
      "current global error: 0.02696483464165786\n",
      "\n",
      "running 416th iteration\n",
      "current global error: 0.026894228407418445\n",
      "\n",
      "running 417th iteration\n",
      "current global error: 0.026823982029574957\n",
      "\n",
      "running 418th iteration\n",
      "current global error: 0.02675409279123628\n",
      "\n",
      "running 419th iteration\n",
      "current global error: 0.026684558002641308\n",
      "\n",
      "running 420th iteration\n",
      "current global error: 0.026615375000822488\n",
      "\n",
      "running 421th iteration\n",
      "current global error: 0.026546541149273992\n",
      "\n",
      "running 422th iteration\n",
      "current global error: 0.02647805383762524\n",
      "\n",
      "running 423th iteration\n",
      "current global error: 0.026409910481318917\n",
      "\n",
      "running 424th iteration\n",
      "current global error: 0.026342108521293633\n",
      "\n",
      "running 425th iteration\n",
      "current global error: 0.02627464542367166\n",
      "\n",
      "running 426th iteration\n",
      "current global error: 0.026207518679450925\n",
      "\n",
      "running 427th iteration\n",
      "current global error: 0.02614072580420161\n",
      "\n",
      "running 428th iteration\n",
      "current global error: 0.026074264337766852\n",
      "\n",
      "running 429th iteration\n",
      "current global error: 0.02600813184396855\n",
      "\n",
      "running 430th iteration\n",
      "current global error: 0.025942325910316644\n",
      "\n",
      "running 431th iteration\n",
      "current global error: 0.025876844147722927\n",
      "\n",
      "running 432th iteration\n",
      "current global error: 0.02581168419021903\n",
      "\n",
      "running 433th iteration\n",
      "current global error: 0.02574684369467849\n",
      "\n",
      "running 434th iteration\n",
      "current global error: 0.025682320340542606\n",
      "\n",
      "running 435th iteration\n",
      "current global error: 0.025618111829550386\n",
      "\n",
      "running 436th iteration\n",
      "current global error: 0.025554215885472336\n",
      "\n",
      "running 437th iteration\n",
      "current global error: 0.025490630253848033\n",
      "\n",
      "running 438th iteration\n",
      "current global error: 0.025427352701727364\n",
      "\n",
      "running 439th iteration\n",
      "current global error: 0.02536438101741552\n",
      "\n",
      "running 440th iteration\n",
      "current global error: 0.025301713010221633\n",
      "\n",
      "running 441th iteration\n",
      "current global error: 0.025239346510210793\n",
      "\n",
      "running 442th iteration\n",
      "current global error: 0.025177279367959805\n",
      "\n",
      "running 443th iteration\n",
      "current global error: 0.02511550945431616\n",
      "\n",
      "running 444th iteration\n",
      "current global error: 0.025054034660160485\n",
      "\n",
      "running 445th iteration\n",
      "current global error: 0.024992852896172285\n",
      "\n",
      "running 446th iteration\n",
      "current global error: 0.024931962092599066\n",
      "\n",
      "running 447th iteration\n",
      "current global error: 0.024871360199028525\n",
      "\n",
      "running 448th iteration\n",
      "current global error: 0.024811045184163966\n",
      "\n",
      "running 449th iteration\n",
      "current global error: 0.02475101503560293\n",
      "\n",
      "running 450th iteration\n",
      "current global error: 0.024691267759618517\n",
      "\n",
      "running 451th iteration\n",
      "current global error: 0.02463180138094449\n",
      "\n",
      "running 452th iteration\n",
      "current global error: 0.02457261394256226\n",
      "\n",
      "running 453th iteration\n",
      "current global error: 0.02451370350549191\n",
      "\n",
      "running 454th iteration\n",
      "current global error: 0.02445506814858515\n",
      "\n",
      "running 455th iteration\n",
      "current global error: 0.02439670596832194\n",
      "\n",
      "running 456th iteration\n",
      "current global error: 0.02433861507860897\n",
      "\n",
      "running 457th iteration\n",
      "current global error: 0.024280793610581962\n",
      "\n",
      "running 458th iteration\n",
      "current global error: 0.024223239712409476\n",
      "\n",
      "running 459th iteration\n",
      "current global error: 0.024165951549100465\n",
      "\n",
      "running 460th iteration\n",
      "current global error: 0.02410892730231366\n",
      "\n",
      "running 461th iteration\n",
      "current global error: 0.024052165170170038\n",
      "\n",
      "running 462th iteration\n",
      "current global error: 0.023995663367067217\n",
      "\n",
      "running 463th iteration\n",
      "current global error: 0.023939420123497254\n",
      "\n",
      "running 464th iteration\n",
      "current global error: 0.023883433685865877\n",
      "\n",
      "running 465th iteration\n",
      "current global error: 0.023827702316314876\n",
      "\n",
      "running 466th iteration\n",
      "current global error: 0.023772224292546603\n",
      "\n",
      "running 467th iteration\n",
      "current global error: 0.023716997907650594\n",
      "\n",
      "running 468th iteration\n",
      "current global error: 0.023662021469932945\n",
      "\n",
      "running 469th iteration\n",
      "current global error: 0.023607293302747624\n",
      "\n",
      "running 470th iteration\n",
      "current global error: 0.02355281174433011\n",
      "\n",
      "running 471th iteration\n",
      "current global error: 0.023498575147633236\n",
      "\n",
      "running 472th iteration\n",
      "current global error: 0.023444581880165113\n",
      "\n",
      "running 473th iteration\n",
      "current global error: 0.02339083032382943\n",
      "\n",
      "running 474th iteration\n",
      "current global error: 0.023337318874767456\n",
      "\n",
      "running 475th iteration\n",
      "current global error: 0.02328404594320256\n",
      "\n",
      "running 476th iteration\n",
      "current global error: 0.02323100995328634\n",
      "\n",
      "running 477th iteration\n",
      "current global error: 0.023178209342947016\n",
      "\n",
      "running 478th iteration\n",
      "current global error: 0.023125642563739803\n",
      "\n",
      "running 479th iteration\n",
      "current global error: 0.023073308080699077\n",
      "\n",
      "running 480th iteration\n",
      "current global error: 0.02302120437219255\n",
      "\n",
      "running 481th iteration\n",
      "current global error: 0.02296932992977725\n",
      "\n",
      "running 482th iteration\n",
      "current global error: 0.02291768325805758\n",
      "\n",
      "running 483th iteration\n",
      "current global error: 0.02286626287454485\n",
      "\n",
      "running 484th iteration\n",
      "current global error: 0.02281506730951901\n",
      "\n",
      "running 485th iteration\n",
      "current global error: 0.022764095105891773\n",
      "\n",
      "running 486th iteration\n",
      "current global error: 0.022713344819071703\n",
      "\n",
      "running 487th iteration\n",
      "current global error: 0.02266281501683119\n",
      "\n",
      "running 488th iteration\n",
      "current global error: 0.022612504279174463\n",
      "\n",
      "running 489th iteration\n",
      "current global error: 0.022562411198208378\n",
      "\n",
      "running 490th iteration\n",
      "current global error: 0.02251253437801352\n",
      "\n",
      "running 491th iteration\n",
      "current global error: 0.022462872434518215\n",
      "\n",
      "running 492th iteration\n",
      "current global error: 0.022413423995373133\n",
      "\n",
      "running 493th iteration\n",
      "current global error: 0.02236418769982795\n",
      "\n",
      "running 494th iteration\n",
      "current global error: 0.022315162198609715\n",
      "\n",
      "running 495th iteration\n",
      "current global error: 0.02226634615380222\n",
      "\n",
      "running 496th iteration\n",
      "current global error: 0.022217738238727365\n",
      "\n",
      "running 497th iteration\n",
      "current global error: 0.022169337137827694\n",
      "\n",
      "running 498th iteration\n",
      "current global error: 0.022121141546550652\n",
      "\n",
      "running 499th iteration\n",
      "current global error: 0.022073150171234037\n",
      "\n",
      "running 500th iteration\n",
      "current global error: 0.022025361728993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the dimensions of the input images\n",
    "image_width, image_height = 16, 16\n",
    "\n",
    "# Set the number of target classes\n",
    "num_of_target = 20\n",
    "\n",
    "# Read numeral training files and their corresponding labels\n",
    "numeral_all_X_train, numeral_all_y_train = \\\n",
    "    training_read_files(\n",
    "        r\"C:/Users/Kuah Jia Chen/Documents/Monash_Resources/Sem 1 2023/FIT3081/Assignment 3/Neural Network/A3_Fill_Training_Dataset_Numeral/\",\n",
    "        num_of_target, image_width, image_height)\n",
    "\n",
    "# Read alphabet training files and their corresponding labels\n",
    "alphabet_all_X_train, alphabet_all_y_train = \\\n",
    "    training_read_files(\n",
    "        r\"C:/Users/Kuah Jia Chen/Documents/Monash_Resources/Sem 1 2023/FIT3081/Assignment 3/Neural Network/A3_New_Fill_Training_Dataset_Alphabet/\",\n",
    "        num_of_target, image_width, image_height)\n",
    "\n",
    "# Combine numeral and alphabet training data and labels\n",
    "all_X_train, all_y_train = numeral_all_X_train + alphabet_all_X_train, numeral_all_y_train + alphabet_all_y_train\n",
    "\n",
    "# Create an instance of the neural network for training\n",
    "neural_network = TrainingNeuralNetwork(image_width * image_height, 40, num_of_target, image_width, image_height)\n",
    "\n",
    "# Set the error limit for convergence\n",
    "error_limit = 5e-05\n",
    "\n",
    "# Set the maximum number of iterations\n",
    "iteration_limit = 500\n",
    "\n",
    "# Initialize the weights and biases of the neural network\n",
    "neural_network.weight_initialization()\n",
    "\n",
    "# Start the training loop\n",
    "for i in range(iteration_limit):\n",
    "    print(\"running {}th iteration\".format(i + 1))\n",
    "    \n",
    "    # Initialize variables for tracking errors and predictions\n",
    "    y_pred = []\n",
    "    global_error = 0\n",
    "    \n",
    "    # Iterate over each training example\n",
    "    for j in range(len(all_X_train)):\n",
    "        # Get the current training example and its label\n",
    "        current_X_train = all_X_train[j]\n",
    "        current_y_train = all_y_train[j]\n",
    "        \n",
    "        # Set the current training example and label in the neural network\n",
    "        neural_network.set_current_X_train_y_train(current_X_train, current_y_train)\n",
    "        \n",
    "        # Perform forward propagation through the network\n",
    "        neural_network.forward_input_hidden()\n",
    "        neural_network.forward_hidden_output()\n",
    "        \n",
    "        # Perform error correction and get the current error and predicted label\n",
    "        current_error, current_y_pred = neural_network.error_correction()\n",
    "        \n",
    "        # Update the global error and store the predicted label\n",
    "        global_error += current_error\n",
    "        y_pred.append(current_y_pred)\n",
    "        \n",
    "        # Perform weight and bias correction for the output layer\n",
    "        neural_network.weight_bias_correction_output()\n",
    "        \n",
    "        # Perform weight and bias correction for the hidden layer\n",
    "        neural_network.weight_bias_correction_hidden()\n",
    "        \n",
    "        # Update the weights and biases\n",
    "        neural_network.weight_bias_update()\n",
    "    \n",
    "    # Print the global error for the current iteration\n",
    "    print(\"current global error: \" + str(global_error))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Check if the network has converged or reached the maximum number of iterations\n",
    "    if neural_network.check_for_end(iteration_limit, error_limit, global_error):\n",
    "        break\n",
    "\n",
    "# Save the final weights and biases of the trained neural network\n",
    "neural_network.saving_weight_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1627b0",
   "metadata": {},
   "source": [
    "The `y_pred` variable stores the final outputs for each training image. Uncomment the following code to print the target outputs for each training image. The results should indicate that the target outputs for each training image are greater than or equal to 0.9, while the remaining 19 outputs are less than 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02ce05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the counter variable\n",
    "# counter = 0\n",
    "\n",
    "# # Iterate over each predicted output\n",
    "# for y_pred_i in y_pred:\n",
    "#     max_pred = max(y_pred_i.reshape(-1))\n",
    "#     print(max_pred)\n",
    "    \n",
    "#     # Check if the maximum predicted value exceeds the threshold\n",
    "#     if max_pred > 0.9:\n",
    "#         counter += 1\n",
    "\n",
    "# # Print the final count and the total number of predictions\n",
    "# print(counter, len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee2f7b",
   "metadata": {},
   "source": [
    "The result of the code demonstrates that the target outputs for each training image exceed or equal 0.9, while the remaining 19 outputs fall below 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "332bd43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of target outputs that are greater or equal to 0.9: 160\n",
      "number of training images used:                            160\n",
      "success rate:                                              100.0%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of elements in y_pred with max value > 0.9\n",
    "counter = sum(max(y.reshape(-1)) > 0.9 for y in y_pred)  \n",
    "# Print the counter and total number of elements in y_pred\n",
    "print(\"number of target outputs that are greater or equal to 0.9: \" + str(counter))\n",
    "print(\"number of training images used:                            \" + str(len(y_pred)))\n",
    "print(\"success rate:                                              \" + str(counter/len(y_pred)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92db468",
   "metadata": {},
   "source": [
    "## Section 2: Testing of the Neural Network Program using Manually Cropped Images\n",
    "\n",
    "In this section, the trained neural network program is tested using manually cropped images. The objective is to evaluate the accuracy of the network's predictions. The testing results show that the accuracy rate is greater than 90%, specifically achieving an accuracy rate of 95%. This high accuracy demonstrates the effectiveness of the trained network in accurately classifying the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87f62b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingNeuralNetwork:\n",
    "\n",
    "    def __init__(self, num_of_input, num_of_hidden, num_of_output, image_width, image_height):\n",
    "        \"\"\"\n",
    "        Initialize the neural network.\n",
    "\n",
    "        Args:\n",
    "        - num_of_input: Number of input nodes.\n",
    "        - num_of_hidden: Number of hidden nodes.\n",
    "        - num_of_output: Number of output nodes.\n",
    "        - image_width: Width of the input image.\n",
    "        - image_height: Height of the input image.\n",
    "        \"\"\"\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_hidden = num_of_hidden\n",
    "        self.num_of_output = num_of_output\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.wji = None\n",
    "        self.wkj = None\n",
    "        self.bias_j = None\n",
    "        self.bias_k = None\n",
    "        self.learning_rate = 0.5\n",
    "        self.error_total = math.inf\n",
    "        self.num_of_epoch = 0\n",
    "\n",
    "    def weight_initialization(self, wji, wkj, bias_j, bias_k):\n",
    "        \"\"\"\n",
    "        Initialize the weights of the neural network.\n",
    "\n",
    "        Args:\n",
    "        - wji: Weight matrix between input and hidden layer.\n",
    "        - wkj: Weight matrix between hidden and output layer.\n",
    "        - bias_j: Bias vector for the hidden layer.\n",
    "        - bias_k: Bias vector for the output layer.\n",
    "        \"\"\"\n",
    "        # Initializing of the Weights.\n",
    "        # Random float number between -0.5 to 0.5.\n",
    "        self.wji = wji\n",
    "        self.wkj = wkj\n",
    "        self.bias_j = bias_j\n",
    "        self.bias_k = bias_k\n",
    "        self.wji = np.array(self.wji)\n",
    "        self.wkj = np.array(self.wkj)\n",
    "        self.bias_j = np.array(self.bias_j)\n",
    "        self.bias_k = np.array(self.bias_k)\n",
    "\n",
    "    def set_current_X_test_y_test(self, current_X_test):\n",
    "        \"\"\"\n",
    "        Set the current test input for the neural network.\n",
    "\n",
    "        Args:\n",
    "        - current_X_test: Test input data.\n",
    "        \"\"\"\n",
    "        self.X_test = current_X_test\n",
    "        self.X_test = np.array(self.X_test)\n",
    "        self.X_test = self.X_test.reshape((self.X_test.shape[0], 1))\n",
    "\n",
    "    def forward_input_hidden(self):\n",
    "        \"\"\"\n",
    "        Perform forward propagation from the input to the hidden layer.\n",
    "        \"\"\"\n",
    "        # Forward Propagation from Input -> Hidden Layer.\n",
    "        # Obtain the results at each neuron in the hidden layer\n",
    "        self.net_j = np.dot(self.wji, self.X_test)\n",
    "        self.out_j = 1 / (1 + np.exp(-(self.net_j + self.bias_j)))\n",
    "\n",
    "    def forward_hidden_output(self):\n",
    "        \"\"\"\n",
    "        Perform forward propagation from the hidden to the output layer.\n",
    "        \"\"\"\n",
    "        # Forward Propagation from Hidden -> Output Layer, j represents the neuron number at K Layer.\n",
    "        self.net_k = np.dot(self.wkj, self.out_j).reshape((-1, 1))\n",
    "        self.out_k = 1 / (1 + np.exp(-(self.net_k + self.bias_k)))\n",
    "\n",
    "    def prediction(self):\n",
    "        \"\"\"\n",
    "        Get the predicted output of the neural network.\n",
    "\n",
    "        Returns:\n",
    "            Predicted output.\n",
    "        \"\"\"\n",
    "        return self.out_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce34cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_read_files(folder, num_of_target, image_height, image_width):\n",
    "    \"\"\"\n",
    "    Function to read input and target files from a specified folder.\n",
    "    Args:\n",
    "    - folder: The directory path where the files are located.\n",
    "    - num_of_target: The number of target classes.\n",
    "    - image_height: The desired height of the image.\n",
    "    - image_width: The desired width of the image.\n",
    "    \"\"\"\n",
    "    # Initialize empty lists for input and target data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for image_file_name in os.listdir(folder):\n",
    "        file_name_path = folder + image_file_name\n",
    "\n",
    "        # Create a list of zeros with length equal to the number of target columns\n",
    "        current_target_column = [0] * num_of_target\n",
    "\n",
    "        # Read the image file and convert it to an array\n",
    "        current_image_array = testing_read_image(file_name_path, image_height, image_width)\n",
    "\n",
    "        # Determine the index of the target column based on the image file name\n",
    "        if image_file_name[3] != \".\":\n",
    "            current_target_column[int(image_file_name[2:4])] = 1\n",
    "        else:\n",
    "            current_target_column[int(image_file_name[2])] = 1\n",
    "\n",
    "        # Append the image array and target column to the respective lists\n",
    "        X_train.append(current_image_array)\n",
    "        y_train.append(current_target_column)\n",
    "\n",
    "    # Return the input images and target labels\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e97e8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_read_image(file_path, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Read and preprocess an image for training.\n",
    "\n",
    "    Args:\n",
    "    - file_path: The path to the image file.\n",
    "    - image_width: The desired width of the image.\n",
    "    - image_height: The desired height of the image.\n",
    "\n",
    "    Returns:\n",
    "        The preprocessed image array.\n",
    "    \"\"\"\n",
    "    # Read the image from the given file path as grayscale\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize the image to the specified width and height\n",
    "    image = cv2.resize(image, (image_width, image_height))\n",
    "    \n",
    "    # Convert the 2D image array to 1D\n",
    "    image = image.flatten()\n",
    "    \n",
    "    # Normalize the pixel values between 0 and 1 by dividing by 255.0\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Return the normalized image array\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c90e2a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy = 95.0 %\n"
     ]
    }
   ],
   "source": [
    "# Set the dimensions of the image and the number of target classes\n",
    "image_width, image_height = 16, 16\n",
    "num_of_target = 20\n",
    "\n",
    "# Load numeral testing dataset\n",
    "numeral_all_X_test, numeral_all_y_test = \\\n",
    "    testing_read_files(\n",
    "        r\"C:/Users/Kuah Jia Chen/Documents/Monash_Resources/Sem 1 2023/FIT3081/Assignment 3/Neural Network/A3_Fill_Testing_Dataset_Numeral/\",\n",
    "        num_of_target, image_width, image_height)\n",
    "\n",
    "# Load alphabet testing dataset\n",
    "alphabet_all_X_test, alphabet_all_y_test = \\\n",
    "    testing_read_files(\n",
    "        r\"C:/Users/Kuah Jia Chen/Documents/Monash_Resources/Sem 1 2023/FIT3081/Assignment 3/Neural Network/A3_New_Fill_Testing_Dataset_Alphabet/\",\n",
    "        num_of_target, image_width, image_height)\n",
    "\n",
    "# Combine all testing data and labels\n",
    "all_X_test, all_y_test = numeral_all_X_test + alphabet_all_X_test, numeral_all_y_test + alphabet_all_y_test\n",
    "\n",
    "# Create an instance of the TestingNeuralNetwork class\n",
    "neural_network = TestingNeuralNetwork(image_width * image_height, 80, num_of_target, image_width, image_height)\n",
    "\n",
    "# Load the weight arrays and bias values from the file\n",
    "data = np.load('output_file.npz')\n",
    "wji = data['wji']\n",
    "wkj = data['wkj']\n",
    "bias_j = data['bias_j']\n",
    "bias_k = data['bias_k']\n",
    "\n",
    "# Initialize the neural network weights and biases\n",
    "neural_network.weight_initialization(wji, wkj, bias_j, bias_k)\n",
    "\n",
    "# Perform prediction on all test samples\n",
    "y_pred = []\n",
    "for i in range(len(all_X_test)):\n",
    "    current_X_test = all_X_test[i]\n",
    "    current_y_test = all_y_test[i]\n",
    "\n",
    "    # Set the current test input and perform forward propagation\n",
    "    neural_network.set_current_X_test_y_test(current_X_test)\n",
    "    neural_network.forward_input_hidden()\n",
    "    neural_network.forward_hidden_output()\n",
    "\n",
    "    # Obtain the predicted output and convert it to binary form\n",
    "    current_y_pred = neural_network.prediction()\n",
    "    output_1d = current_y_pred.reshape(-1)\n",
    "    max_index = np.argmax(output_1d)\n",
    "    binary_array = [0] * num_of_target\n",
    "    binary_array[max_index] = 1\n",
    "    y_pred.append(binary_array)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "counter = 0\n",
    "for i in range(len(y_pred)):\n",
    "    current_y_test = all_y_test[i]\n",
    "    current_y_pred = y_pred[i]\n",
    "    if np.argmax(current_y_test) == np.argmax(current_y_pred):\n",
    "        counter += 1\n",
    "accuracy = counter / len(y_pred)\n",
    "\n",
    "# Print the accuracy and the number of test samples\n",
    "print(\"testing accuracy = {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d17fd",
   "metadata": {},
   "source": [
    "## Section 3: Testing of Malaysian Car Number Plate Recognition\n",
    "\n",
    "In this section, the trained neural network program is applied to test the recognition of Malaysian car number plates. The aim is to assess the network's performance on real-world data. The testing results reveal that the accuracy rate for car number plate recognition is greater than 90%, achieving an accuracy rate of 91%. This demonstrates the capability of the trained network to accurately recognize and classify Malaysian car number plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23c000c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActualTestingNeuralNetwork:\n",
    "\n",
    "    def __init__(self, num_of_input, num_of_hidden, num_of_output, image_width, image_height):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with the given parameters.\n",
    "        \n",
    "        Args:\n",
    "        - num_of_input: Number of input neurons.\n",
    "        - num_of_hidden: Number of hidden neurons.\n",
    "        - num_of_output: Number of output neurons.\n",
    "        - image_width: Width of the input image.\n",
    "        - image_height: Height of the input image.\n",
    "        \"\"\"\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_hidden = num_of_hidden\n",
    "        self.num_of_output = num_of_output\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.wji = None\n",
    "        self.wkj = None\n",
    "        self.bias_j = None\n",
    "        self.bias_k = None\n",
    "        self.learning_rate = 0.5\n",
    "        self.error_total = math.inf\n",
    "        self.num_of_epoch = 0\n",
    "\n",
    "    def weight_initialization(self, wji, wkj, bias_j, bias_k):\n",
    "        \"\"\"\n",
    "        Initialize the weights and biases of the neural network.\n",
    "        \n",
    "        Args:\n",
    "        - wji: Weight matrix between input and hidden layer.\n",
    "        - wkj: Weight matrix between hidden and output layer.\n",
    "        - bias_j: Bias vector for the hidden layer.\n",
    "        - bias_k: Bias vector for the output layer.\n",
    "        \"\"\"\n",
    "        # Initializing the weights\n",
    "        self.wji = wji\n",
    "        self.wkj = wkj\n",
    "        self.bias_j = bias_j\n",
    "        self.bias_k = bias_k\n",
    "        self.wji = np.array(self.wji)\n",
    "        self.wkj = np.array(self.wkj)\n",
    "        self.bias_j = np.array(self.bias_j)\n",
    "        self.bias_k = np.array(self.bias_k)\n",
    "\n",
    "    def set_current_X_test_y_test(self, current_X_test):\n",
    "        \"\"\"\n",
    "        Set the current input test data.\n",
    "        \n",
    "        Args:\n",
    "        - current_X_test: Input test data.\n",
    "        \"\"\"\n",
    "        self.X_test = current_X_test\n",
    "        self.X_test = np.array(self.X_test)\n",
    "        self.X_test = self.X_test.reshape((self.X_test.shape[0], 1))\n",
    "\n",
    "    def forward_input_hidden(self):\n",
    "        \"\"\"\n",
    "        Perform forward propagation from input to hidden layer.\n",
    "        \"\"\"\n",
    "        # Forward propagation from input to hidden layer\n",
    "        self.net_j = np.dot(self.wji, self.X_test)\n",
    "        self.out_j = 1 / (1 + np.exp(-(self.net_j + self.bias_j)))\n",
    "\n",
    "    def forward_hidden_output(self):\n",
    "        \"\"\"\n",
    "        Perform forward propagation from hidden to output layer.\n",
    "        \"\"\"\n",
    "        # Forward propagation from hidden to output layer\n",
    "        self.net_k = np.dot(self.wkj, self.out_j).reshape((-1, 1))\n",
    "        self.out_k = 1 / (1 + np.exp(-(self.net_k + self.bias_k)))\n",
    "\n",
    "    def prediction(self):\n",
    "        \"\"\"\n",
    "        Get the predicted output of the neural network.\n",
    "        \n",
    "        Returns:\n",
    "        - Predicted output.\n",
    "        \"\"\"\n",
    "        return self.out_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a6c055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_testing_read_files(folder, num_of_target, image_height, image_width):\n",
    "    \"\"\"\n",
    "    Read input and target files from the specified folder.\n",
    "\n",
    "    Args:\n",
    "    - folder: Path to the folder containing the files.\n",
    "    - num_of_target: Number of target classes.\n",
    "    - image_height: Height of the input image.\n",
    "    - image_width: Width of the input image.\n",
    "\n",
    "    Returns:\n",
    "    - X_train: List of input images.\n",
    "    - y_train: List of corresponding target labels.\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Iterate over files in the folder\n",
    "    for image_file_name in os.listdir(folder):\n",
    "        file_name_path = folder + image_file_name\n",
    "\n",
    "        # Initialize target column with zeros\n",
    "        current_target_column = [0] * num_of_target\n",
    "\n",
    "        np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "        # Read the image file and convert it to an array\n",
    "        current_image_array = actual_testing_read_image(file_name_path, image_height, image_width)\n",
    "\n",
    "        # Set the target column value for the corresponding class\n",
    "        current_target_column[int(image_file_name[2:4])] = 1\n",
    "\n",
    "        # Append the input image and target column to the respective lists\n",
    "        X_train.append(current_image_array)\n",
    "        y_train.append(current_target_column)\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "664ebfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_testing_read_image(file_path, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Read and preprocess an image for actual testing.\n",
    "    \n",
    "    Args:\n",
    "    - file_path: Path to the image file.\n",
    "    - image_width: Desired width of the image.\n",
    "    - image_height: Desired height of the image.\n",
    "    \n",
    "    Returns:\n",
    "    - Preprocessed image array.\n",
    "    \"\"\"\n",
    "    # Set numpy printing options to display the entire array\n",
    "    \n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Read the image as grayscale\n",
    "    image = cv2.resize(image, (image_width, image_height))  # Resize the image if needed\n",
    "    image = image.flatten()  # Convert the 2D image array to 1D\n",
    "    image = image.astype(np.float32) / 255.0  # Normalize the pixel values between 0 and 1\n",
    "    \n",
    "    # return the image array\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "234ae198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 91.30434782608695 % (63 / 69)\n"
     ]
    }
   ],
   "source": [
    "# Set the image width, image height, and number of target classes\n",
    "image_width, image_height = 16, 16\n",
    "num_of_target = 20\n",
    "\n",
    "# Initialize lists to store all input test data and target test data\n",
    "all_X_test, all_y_test = [], []\n",
    "\n",
    "# Read files and collect input test data and target test data\n",
    "for i in range(10):\n",
    "    current_X_test, current_y_test = actual_testing_read_files(\n",
    "        r\"C:/Users/Kuah Jia Chen/Documents/Monash_Resources/Sem 1 2023/FIT3081/Assignment 3/Neural Network/Segmentation/LP{}/\".format(\n",
    "            i + 1),\n",
    "        num_of_target, image_width, image_height)\n",
    "    all_X_test += current_X_test\n",
    "    all_y_test += current_y_test\n",
    "\n",
    "# Create an instance of the ActualTestingNeuralNetwork class\n",
    "neural_network = ActualTestingNeuralNetwork(image_width * image_height, 80, num_of_target, image_width, image_height)\n",
    "\n",
    "# Load the weight and bias arrays from the file\n",
    "data = np.load('output_file.npz')\n",
    "wji = data['wji']\n",
    "wkj = data['wkj']\n",
    "bias_j = data['bias_j']\n",
    "bias_k = data['bias_k']\n",
    "\n",
    "# Initialize the neural network with the loaded weights and biases\n",
    "neural_network.weight_initialization(wji, wkj, bias_j, bias_k)\n",
    "\n",
    "# Make predictions for all input test data\n",
    "y_pred = []\n",
    "for i in range(len(all_X_test)):\n",
    "    current_X_test = all_X_test[i]\n",
    "    current_y_test = all_y_test[i]\n",
    "    \n",
    "    # Set the current input test data and target test data\n",
    "    neural_network.set_current_X_test_y_test(current_X_test)\n",
    "    \n",
    "    # Perform forward propagation to get the predicted output\n",
    "    neural_network.forward_input_hidden()\n",
    "    neural_network.forward_hidden_output()\n",
    "    current_y_pred = neural_network.prediction()\n",
    "\n",
    "    # Convert the predicted output to a binary array\n",
    "    output_1d = current_y_pred.reshape(-1)\n",
    "    max_index = np.argmax(output_1d)\n",
    "    binary_array = [0] * num_of_target\n",
    "    binary_array[max_index] = 1\n",
    "\n",
    "    y_pred.append(binary_array)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "counter = 0\n",
    "misclassified = []\n",
    "for i in range(len(y_pred)):\n",
    "    current_y_test = all_y_test[i]\n",
    "    current_y_pred = y_pred[i]\n",
    "    \n",
    "    # Check if the prediction matches the target\n",
    "    if np.argmax(current_y_test) == np.argmax(current_y_pred):\n",
    "        counter += 1\n",
    "    else:\n",
    "        misclassified.append([np.argmax(current_y_test), np.argmax(current_y_pred)])\n",
    "\n",
    "# Calculate and display the accuracy\n",
    "accuracy = counter / len(y_pred)\n",
    "print(\"accuracy = {} % ({} / {})\".format(accuracy * 100, str(counter), str(len(all_y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08735e25",
   "metadata": {},
   "source": [
    "We evaluated the performance of the neural network program for recognizing Malaysian car number plates, and the results were highly promising. The accuracy rate surpassed 90%, specifically reaching an impressive accuracy rate of 91%, indicating the neural network's ability to effectively classify car number plates. Out of a total of 69 characters, the neural network successfully classified 63 characters correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38656a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(num):\n",
    "    \"\"\"\n",
    "    Get the label corresponding to the given number.\n",
    "\n",
    "    Args:\n",
    "    - num: Number for which to retrieve the label.\n",
    "\n",
    "    Returns:\n",
    "    - Label corresponding to the number.\n",
    "    \"\"\"\n",
    "    if 0 <= num <= 9:\n",
    "        return str(num)\n",
    "    elif num == 10:\n",
    "        return \"B\"\n",
    "    elif num == 11:\n",
    "        return \"F\"\n",
    "    elif num == 12:\n",
    "        return \"L\"\n",
    "    elif num == 13:\n",
    "        return \"M\"\n",
    "    elif num == 14:\n",
    "        return \"P\"\n",
    "    elif num == 15:\n",
    "        return \"Q\"\n",
    "    elif num == 16:\n",
    "        return \"T\"\n",
    "    elif num == 17:\n",
    "        return \"U\"\n",
    "    elif num == 18:\n",
    "        return \"V\"\n",
    "    # elif num == 19:\n",
    "    else:\n",
    "        return \"W\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc4ab9",
   "metadata": {},
   "source": [
    "However, the obtained results reveal that our neural network struggles with correctly classifying the character \"B\" and often predicts it as \"8\" or \"U\". This indicates an area where our network can be improved. One approach to enhancing the network's performance in this regard is by training it with higher quality images specifically focusing on the character \"B\". Additionally, implementing more effective preprocessing techniques can also contribute to improving the overall accuracy of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75e95c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: B\n",
      "Predicted label: 8\n",
      "\n",
      "Actual label: B\n",
      "Predicted label: 8\n",
      "\n",
      "Actual label: B\n",
      "Predicted label: 8\n",
      "\n",
      "Actual label: B\n",
      "Predicted label: 8\n",
      "\n",
      "Actual label: B\n",
      "Predicted label: U\n",
      "\n",
      "Actual label: B\n",
      "Predicted label: U\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visualize_misclassified_data = []\n",
    "\n",
    "# Iterate over misclassified data and create a list of labels for visualization.\n",
    "for actual_label, predicted_label in misclassified:\n",
    "    actual_label = get_label(actual_label)\n",
    "    predicted_label = get_label(predicted_label)\n",
    "    visualize_misclassified_data.append([actual_label, predicted_label])\n",
    "\n",
    "# Print the actual and predicted labels for each misclassified data.\n",
    "for data in visualize_misclassified_data:\n",
    "    print(\"Actual label: \" + data[0])\n",
    "    print(\"Predicted label: \" + data[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d16be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual number plates:  ['VBU3878', 'WUM207', 'VBT2597', 'WTF6868', 'PLW7969', 'BPU9859', 'BMT8628', 'BMB8262', 'PPV7422', 'BQP8189']\n",
      "predicted number plates: ['V8U3878', 'WUM207', 'V8T2597', 'WTF6868', 'PLW7969', '8PU9859', '8MT8628', 'UMB8262', 'PPV7422', 'UQP8189']\n"
     ]
    }
   ],
   "source": [
    "index = [7, 6, 7, 7, 7, 7, 7, 7, 7, 7]\n",
    "actual = []\n",
    "predicted = []\n",
    "i = 0\n",
    "pointer = 0\n",
    "while i < len(all_X_test):\n",
    "    actual.append(all_y_test[i:i+index[pointer]])\n",
    "    predicted.append(y_pred[i:i+index[pointer]])\n",
    "    i += index[pointer]\n",
    "    pointer += 1\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "for i in range(10):\n",
    "    current_actual = actual[i]\n",
    "    current_predicted = predicted[i]\n",
    "    actual_characters = []\n",
    "    predicted_characters = []\n",
    "    for j in range(len(current_actual)):\n",
    "        actual_characters.append(get_label(np.argmax(current_actual[j])))\n",
    "        predicted_characters.append(get_label(np.argmax(current_predicted[j])))\n",
    "    actual_output.append(actual_characters)\n",
    "    predicted_output.append(predicted_characters)\n",
    "\n",
    "final_actual = []\n",
    "final_predicted = []\n",
    "for i in range(len(actual_output)):\n",
    "    final_actual.append(\"\".join(actual_output[i]))\n",
    "    final_predicted.append(\"\".join(predicted_output[i]))\n",
    "    \n",
    "print(\"actual number plates: \", final_actual)\n",
    "print(\"predicted number plates:\", final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9ec8a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Overall, the project showcases the successful application of image processing techniques and neural networks for image classification and car number plate recognition. The high accuracy rates achieved in both testing sections indicate the effectiveness and reliability of the implemented solution in accurately identifying and classifying images and car number plates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
